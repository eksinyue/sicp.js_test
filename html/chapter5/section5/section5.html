<div id='permalink-msg'>
<div class='screen'>
	<div class='alert alert-success'>
		<strong>Permalink copied!</strong>
	</div>
</div>
</div>

<div class='chapter-content'>
<div class='chapter-title'>
	<div class='permalink'>
		<a name='top' class='permalink'>5.5  Compilation</a>
	</div>
</div>
	<div class='chapter-text'>
		<div class='SECTION'><SECTION>\begin{center}\fbox{\textcolor{red}{Note: this section is a work in progress!}}\end{center}

    <SECTIONCONTENT></SECTIONCONTENT>

    
    
    <div class='permalink'>
<a name='p1' class='permalink'></a><p>
      The explicit-control evaluator of section \ref{sec:eceval} is a
      register machine whose controller interprets <SPLIT>JavaScript</SPLIT> programs.  In this
      section we will see how to run <SPLIT>JavaScript</SPLIT> programs on a register machine
      whose controller is not a <SPLIT>JavaScript</SPLIT> interpreter.
    </p></div>

    <div class='permalink'>
<a name='p2' class='permalink'></a><p>
      
      
      The explicit-control evaluator machine is universal—it can carry out
      any computational process that can be described in <SPLIT>JavaScript</SPLIT>.  The
      evaluator's controller orchestrates the use of its data paths to
      perform the desired computation.  Thus, the evaluator's data paths are
      universal: They are sufficient to perform any computation we desire,
      given an appropriate 
      controller.<a class='superscript' id='footnote-link-1' href='#footnote-1'>[1]</a>
    </p></div>

    <div class='permalink'>
<a name='p3' class='permalink'></a><p>
      
      
      Commercial general-purpose computers are register machines organized
      around a collection of registers and operations that constitute
      an efficient and convenient universal set of data paths.
      The controller for a general-purpose machine is an interpreter for
      a register-machine language like the one we have been using.  This
      language is called the 
      
      <EM>native language</EM> of the machine, or simply
      
      <EM>machine language</EM>.  Programs written in machine language are
      sequences of instructions that use the machine's data paths.
      For example, the 
      
      explicit-control evaluator's instruction sequence
      can be thought of as a machine-language program for a general-purpose
      computer rather than as the controller for a specialized interpreter
      machine.
    </p></div>

    <div class='permalink'>
<a name='p4' class='permalink'></a><p>
      
      
      There are two common strategies for bridging the gap between
      higher-level languages and register-machine languages.  The
      explicit-control evaluator illustrates the
      strategy of interpretation.  An interpreter written in the native
      language of a machine configures the machine to execute programs
      written in a language (called the 
      
      <EM>source language</EM>) that may
      differ from the native language of the machine performing the
      evaluation.  The primitive
      functions
      of the source language are
      implemented as a library of subroutines written in the native language
      of the given machine.  A program to be interpreted (called the 
      
      <EM>
  source program</EM>) is represented as a data structure.  The interpreter
      traverses this data structure, analyzing the source program.  As it
      does so, it simulates the intended behavior of the source program by
      calling appropriate primitive subroutines from the library.
    </p></div>

    <div class='permalink'>
<a name='p5' class='permalink'></a><p>
      In this section, we explore the alternative strategy of <EM>
  compilation</EM>.  A compiler for a given source language and machine
      translates a source program into an equivalent program (called the
      
      <EM>object program</EM>) written in the machine's native language.  The
      compiler that we implement in this section translates programs written
      in <SPLIT>JavaScript</SPLIT> into sequences of instructions to be executed using
      the explicit-control evaluator machine's data 
      paths.<a class='superscript' id='footnote-link-2' href='#footnote-2'>[2]</a>
    </p></div>

    <div class='permalink'>
<a name='p6' class='permalink'></a><p>
      Compared with interpretation, compilation can provide a great increase
      in the efficiency of program execution, as we will explain below in
      the overview of the compiler.  On the other hand, an interpreter
      provides a more powerful environment for interactive program
      development and debugging, because the source program being executed
      is available at run time to be examined and modified.  In addition,
      because the entire library of primitives is present, new programs can
      be constructed and added to the system during debugging.
    </p></div>

    <div class='permalink'>
<a name='p7' class='permalink'></a><p>
      In view of the complementary advantages of compilation and
      interpretation, modern program-development environments pursue a mixed
      strategy.  JavaScript interpreters are generally organized so that
      interpreted
      functions
      and compiled
      functions
      can call each other.
      This enables a programmer to compile those parts of a program that are
      assumed to be debugged, thus gaining the efficiency advantage of
      compilation, while retaining the interpretive mode of execution for
      those parts of the program that are in the flux of interactive
      development and debugging.  In
      section \ref{sec:interfacing-compiled-code}, after we have implemented
      the compiler, we will show how to interface it with our interpreter to
      produce an integrated interpreter-compiler development system.
      
      
      
    </p></div>

    <div class='permalink'>
<a name='h1' class='permalink'></a><h2>
      An overview of the compiler
    </h2></div>

    
    

    <div class='permalink'>
<a name='p8' class='permalink'></a><p>
      Our compiler is much like our interpreter, both in its structure and in
      the function it performs.  Accordingly, the mechanisms used by the
      compiler for analyzing expressions will be similar to those used by
      the interpreter.  Moreover, to make it easy to interface compiled and
      interpreted code, we will design the compiler to generate code that
      obeys the same conventions of 
      
      register usage as the interpreter: The
      environment will be kept in the <kbd>env</kbd> register, argument lists
      will be accumulated in <kbd>argl</kbd>, a
      function
      to be applied will be
      in <kbd>proc</kbd>,
      functions
      will return their answers in <kbd>val</kbd>,
      and the location to which a
      function
      should return will be kept in
      <kbd>continue</kbd>.
      In general, the compiler translates a source program into an object
      program that performs essentially the same register operations as
      would the interpreter in evaluating the same source program.
    </p></div>

    <div class='permalink'>
<a name='p9' class='permalink'></a><p>
      This description suggests a strategy for implementing a rudimentary
      compiler: We traverse the expression in the same way the
      interpreter does.  When we encounter a register instruction that the
      interpreter would perform in evaluating the expression, we do not
      execute the instruction but instead accumulate it into a sequence.  The
      resulting sequence of instructions will be the object code.  Observe
      the 
      
      
      efficiency advantage of compilation over interpretation.  Each
      time the interpreter evaluates an expression—for example,
      <kbd>f(84, 96)</kbd>—it performs the work of
      classifying the expression (discovering that this
      is a
      function
      application) and testing for the end of the operand list
      (discovering that there are two operands).  With a
      compiler, the expression is analyzed only once, when the
      instruction sequence is generated at compile time.  The object code
      produced by the compiler contains only the instructions that evaluate
      the operator and the two operands, assemble the argument list,
      and apply the
      function
      (in <kbd>proc</kbd>) to the arguments (in <kbd>argl</kbd>).
    </p></div>

    <div class='permalink'>
<a name='p10' class='permalink'></a><p>
      
      This is the same kind of optimization we implemented in the
      analyzing evaluator of section \ref{sec:separating-analysis}.
      But there are further opportunities to gain efficiency in compiled code.
      As the interpreter runs, it follows a process that must be applicable
      to any expression in the language.  In contrast, a given segment of
      compiled code is meant to execute some particular expression.  This
      can make a big difference, for example in the use of the stack to
      save registers.  When the interpreter evaluates an expression, it must
      be prepared for any contingency.  Before evaluating a subexpression,
      the interpreter saves all
      registers that will be needed later, because
      the subexpression might require an arbitrary evaluation.
      A compiler, on the other hand, can exploit the structure of the
      particular expression it is processing to generate code that avoids
      unnecessary stack operations.
    </p></div>

    <div class='permalink'>
<a name='p11' class='permalink'></a><p>
      As a case in point, consider the combination <kbd>f(84, 96)</kbd>.  Before
      the interpreter evaluates the operator of the combination, it prepares
      for this evaluation by saving the registers containing the operands
      and the environment, whose values will be needed later.  The
      interpreter then evaluates the operator to obtain the result in <kbd>val</kbd>, restores the saved registers, and finally moves the result from
      <kbd>val</kbd> to <kbd>proc</kbd>.  However, in the particular expression we are
      dealing with, the operator is the symbol <kbd>f</kbd>, whose evaluation is
      accomplished by the machine operation <kbd>lookup_variable_value</kbd>,
      which does not alter any registers.  The compiler that we implement in
      this section will take advantage of this fact and generate code that
      evaluates the operator using the instruction
      <div class='snippet' id='javascript_113_1_div'><div class='pre-prettyprint'><pre class='prettyprint no-eval'>
assign("proc", op("lookup_variable_value"), constant("f"), reg("env"));
</pre></div></div>
      This code not only avoids the unnecessary saves and
      restores but also assigns the value of the lookup directly to
      <kbd>proc</kbd>, whereas the interpreter would obtain the result in <kbd>val</kbd>
      and then move this to <kbd>proc</kbd>.
    </p></div>

    <div class='permalink'>
<a name='p12' class='permalink'></a><p>
      A compiler can also optimize access to the environment.  Having
      analyzed the code, the compiler can in many cases know in which frame
      a particular variable will be located and access that frame directly,
      rather than performing the <kbd>lookup_variable_value</kbd> search.  We
      will discuss how to implement such variable access in
      section \ref{sec:lexical-addressing}.  Until then, however, we will
      focus on the kind of register and stack optimizations described above.
      There are many other optimizations that can be performed by a
      compiler, such as coding primitive operations <QUOTE>in line</QUOTE> instead of
      using a general <kbd>apply</kbd> mechanism (see
      exercise \ref{ex:open-code}); but we will not emphasize these here.
      Our main goal in this section is to illustrate the compilation process
      in a simplified (but still interesting) context.
      
      
    </p></div>

    <hr><div class='footnote'>
<a class='footnote-number' id='footnote-1' href='#footnote-link-1'>[1] </a><FOOTNOTE>This is a theoretical statement.  We are not claiming
  that the evaluator's data paths are a particularly convenient or
  efficient set of data paths for a general-purpose computer.  For example,
  they are not very good for implementing high-performance floating-point
  calculations or calculations that intensively manipulate bit vectors.</FOOTNOTE></div><div class='footnote'>
<a class='footnote-number' id='footnote-2' href='#footnote-link-2'>[2] </a><FOOTNOTE>Actually, the machine that runs
  compiled code can be simpler than the interpreter machine, because we
  
  won't use the <kbd>exp</kbd> and <kbd>unev</kbd> registers.  The interpreter
  used these to hold pieces of unevaluated expressions.  With the
  compiler, however, these expressions get built into the
  compiled code that the register machine will run.  For the same
  reason, 
  
  we don't need the machine operations that deal with expression
  syntax.  But compiled code will use a few additional machine
  operations (to represent compiled
  function
  objects) that didn't
  appear in the explicit-control evaluator machine.</FOOTNOTE></div>
</SECTION><div class='nav'>
<button type='button' class='btn btn-secondary' style='background-color: #fff;'>
<a href='/Users/xinyue/Documents/nus/y1s2/CP3108/sicp.js_test/html/chapter5/section4/subsection4.html'>&lt; Previous</a>
</button><div style='flex-grow: 1;'></div>
<button type='button' class='btn btn-secondary' style='background-color: #fff;'>
<a class='scroll-next' href='/Users/xinyue/Documents/nus/y1s2/CP3108/sicp.js_test/html/chapter5/section5/subsection1.html'>Next &gt;</a>
</button></div><div class='chapter_sign'>
5.5  Compilation</div>	<div class='next-page'></div></div>